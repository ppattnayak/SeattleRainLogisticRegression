---
title: "Predicting Rainfall at Seattle Tacoma Airport - Logistic Regression"
author: "Priyaranjan Pattnayak"
date: "December 21, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


##Logistic Regression to predict rain probability in SEATAC International Airport


##Pre-requisites

Previous knowledge of logistic regression is not required. However, basic working knowledge of R commands, linear models and basic data analytics/statistics concepts are required. 

We will only use ROCR, XLConnect, tidyverse, dplyr, plyr, Amelia, ModelMetrics and caTools.

##What is Logistic Regression?

Logistic Regression is a classification algorithm. It is used to predict a categorical outcome (1 / 0, Yes / No, True / False) given a set of independent variables. To represent binary / categorical outcome, we use dummy variables. It can also be considered as a special case of linear regression when the outcome variable is categorical, where we are using log of odds as dependent variable. In simple words, it predicts the probability of occurrence of an event by fitting data to a logit function.

A classical example used in machine learning is email classification: given a set of attributes for each email such as number of words, links and pictures, the algorithm should decide whether the email is spam (1) or not (0).

Reason why logistic Regression is preferred over linear regression, when decision variable is categorical is[1]:

1. If we use linear regression, the predicted values will become greater than one and less than zero if we move far enough on the X-axis. Such values are theoretically inadmissible.

2. One of the assumptions of regression is that the variance of Y is constant across values of X (homoscedasticity). This cannot be the case with a binary variable, because the variance is PQ. When 50 percent of the people are 1s, then the variance is .25, its maximum value. As we move to more extreme values, the variance decreases. When P=.10, the variance is .1*.9 = .09, so as P approaches 1 or zero, the variance approaches zero.

3. The significance testing of the b weights rest upon the assumption that errors of prediction (Y-Y') are normally distributed. Because Y only takes the values 0 and 1, this assumption is pretty hard to justify, even approximately. Therefore, the tests of the regression weights are suspect if you use linear regression with a binary DV.

##Scope of this Project

This project will provide a step-by-step guide for building a logistic regression model using R. Here, we will be using a **'binomial logistic regression'**, as the decision variable can have only two values. However, we can also predict a decision variable with more than three vallues, using logistic regression. This type of regression is called **'Multinomial Logistic Regression'**. In this project, we predict the probablity of rainfall at SEATAC airport in Seattle.

```{r echo=FALSE, message=FALSE, error=FALSE, warning=FALSE}
library(ROCR)
library(XLConnect)
library(tidyverse)
library(dplyr)
library(plyr)
library(Amelia)
library(ModelMetrics)
library(caTools)
```


##Data Source

**National Climatic Data Center**[Link](https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00024233/detail)


Read the data from the csv file (Remember to replace the filepath)

```{r}
rain_data <- read.csv("G:\\RProject\\SeattleRain Logistic Regression\\RainSeattle2016.csv", header=T,na.strings = c(""))
```

The Dataset has below fields:

Rain is the column which we are trying to predict.

NAME is the place where the weather data was recorded on respective DATE.

PRCP and SNOW = Precipitation and Snow in inches

SNWD = Snow depth

TAVG = Average Temperature in F

TMAX, TMIN = max and Min Temperature of the day in F.

WDF5, WSF5 - Direction of fastest 5-second wind in degree and Fastest 5-second wind speed respectively.


Next, we check for missing values.
Amelia library gives us a missmap function that shows the missing details in a visual map.

```{r}
missmap(rain_data,main="Missing Values in Data Set")
```

We have lots of missing values in Fog column. And high winds, sleet, hail, smoke, thunder and heavy fog are unuseable as they have almost all missing values.
Therefore, we can exclude them from our model.

Name, Days, DATE, PRCP and SNWD can also be ignored.
Only include the columns that we would be using for building a model.

In our case, we only use Rain, Season, Ave.wind, PRCP, TAVG, TMAX, TMIN, WDF5 and WSF5

```{r}
rain_df <- subset(rain_data,select=c(1,3,4,5,7,8,9,10,11,12,13))
```

Sneak-peak into the data:

```{r}
head(rain_df)
```


Before we proceed, let's see if our subset has any NA values.
In case missing values are observed, we need to account for them.
One of the most common ways to exclude the rows containing NA values or fit missing values by inserting the median value of that column.
One can also plot box-plots to find appropriate value for the missing value. Or use Knn/mice/Amelia imputation.

```{r}
sapply(rain_df,function(x) sum(is.na(x)))
```


We **don't have missing** values.

Now that we have the data in place, we need to modify the few columns from continuous type to categorical type.
In many data analysis settings, it might be useful to break up a continuous variable such as age into a categorical variable. 
Or, one might want to classify a categorical variable like year into a larger bin, such as 1990-2000

Here, we categorize two columns in the dataset.
First, Rain is converted to a factor with 2 levels i.e 0 and 1. 0 indicates no rain, whereas 1 indicates rainfall on that day.

```{r}
rain_df$Rain <- factor(rain_df$Rain)
```

Next, we create an unordered categorical variable for Season.

```{r}
rain_df$Season <- factor(rain_df$Season,ordered = FALSE)
```

Season is now a factorial variable with 4 levels i.e 'Fall', 'Soring', 'Summer', 'Winter'. 
Ordered = FALSE indicates R that the categories are not ordinal.

We  need to convert DATE from character type to date type.
We do that by using the as.Date() function.

```{r}
rain_df$DATE <- as.Date(rain_df$DATE,'%m/%d/%Y')
```

Before we proceed, let's see how R is going to deal with the categorical variables. We can use the contrasts() function for this. 
This function shows us how the variables have been dummyfied by R and how to interpret them in a model.
It shows us the reference values for each factorial variable.

```{r}
contrasts(rain_df$Rain)
contrasts(rain_df$Season)
```

In Season category, class 'Fall' is used as reference.

The Generalized Linear Models in R internally encode categorical variables into n - 1 distinct levels.
Thus, glm() in R will use one category of Season and use it as reference against remaining three categories in the model.
Model statistics will indicate the significance of each of those three levels.
Later, we will check if the categorical variable Season is statistically significant as a whole.


We split the data into training and test data set. Training set will be used to build the model
And test data can be used to tes the model fit.
One can also use n-fold cross validation for better results.

We will split 80% of data into training and 20% into test set.

```{r}
set.seed(88)
split <- sample.split(rain_df$Rain,SplitRatio = 0.8)
```

Build the training and test chunks.

```{r}
train_df <- subset(rain_df,split==TRUE)
test_df <- subset(rain_df,split==FALSE)
```


Let's fit the model to our data.
The code below estimates a logistic regression model using the glm (generalized linear model) function. 
Be sure to specify the parameter family=binomial in the glm() function.

```{r}
glm1 <- glm(Rain ~ Season+Ave.Wind+SNOW+TAVG+TMAX+TMIN+WDF5+WSF5,family = binomial(link = "logit"),data = train_df)
```

####Model Statistics

```{r}
summary(glm1)
```

Interpreting the results of our regression model

The glm function internally encodes categorical variables into n - 1 distinct levels, as mentioned earlier.
Here, the regression coefficients explain the change in log(odds) of the response variable for one unit change in the predictor variable.
Std. Error represents the standard error associated with the regression coefficients.
z value(sometimes called a Wald z-statistic) is analogous to t-statistics in multiple regression output.
p value has the same interpretation as that in linear regression. With 95% confidence level, a variable having p < 0.05 is considered an important predictor.

In the above model(glm1), SNOW is least significant. And TMAX is the most significant.
This means, with all other variables remaining constant, SNOW has the least effect on rain probablity and TMAX has highest effect.
For every one unit change in TMAX, log odds of rain reduces by 2.902e-01 times.

Below the table of coefficients are fit indices, including the null and deviance residuals and the AIC. 
AIC and the residuals are crucial in determining model fit. Model with lower AIC is almost always preferred.

Next step is to analyze the deviance table.
We do that by doing a ANOVA Chi-square test to check the overall effect of variables on the dependent variable.


```{r}
anova(glm1,test='Chisq')
```

Null Deviance - Residual Deviance shows our model's performance as compared to a model with no variables(only the intercept) a.k.a the null model.
The wider the gap, the better is the model.
In addition, lower null and residual deviance are preferred, whereever applicable.
Every time a variable is added, deviance drops. We need to identify those variable that do not cause large drop in deviance.
A large p-value here indicates that the model without the variable explains more or less the same amount of variation.

It's interesting to notice that Season as a whole is highly significant, but at categorical level, Season(or rather Spring/Summer/Winter) are not significant, not at least in the first model.
Here, variables WDF5, SNOW and TAVG are not significant. We can remove them sequentially and rebuild glm models and repeat the whole process until all variables are significant.
AIC for glm1 was 257.56

After sequentially eliminating SNOW followed by WDF5 and TAVG, we come accross the below model.

```{r}
glm2 <- glm(Rain ~ Season+Ave.Wind+TMAX+TMIN+WSF5,family = binomial(link = "logit"),data = train_df)
summary(glm2)
```

Note that, the Ave.Wind variable is being considered as non-significant. Let's see the ANOVA deviance table.

```{r}
anova(glm2, test='Chisq')
```

ANOVA instead tells us that Ave.Wind is significant. It is important to note how anova performs the test.
Sequentially compares the smaller model with the next more complex model by adding one variable in each step. Each of those comparisons is done via a likelihood ratio test.

We need to build two models, one with Ave.wind and another without Ave.WInd and then compare the two models and pick the better among them.
Note the AIC of glm2 = 252.95
Remove Ave.Wind and build a model

```{r}
glm3 <- glm(Rain ~ Season+TMAX+TMIN+WSF5,family = binomial(link = "logit"),data = train_df)
summary(glm3)
```

```{r}
anova(glm3, test='Chisq')
```

Compare the two models in anova:

Our NULL hypothesis is that co-efficient of Ave.Wind is 0. 
Therefore, if p <0.05, we can reject NULL hypothesis and say that the additional variable must remain in the final model.

```{r}
anova(glm2,glm3,test='Chisq')
```

P = 0.15 and we stick with NULL hypothesis i.e co-efficient of Ave.Wind is 0. 
Therefore, we pick glm3 to proceed.

Looking back at coefficients of glm3, we can see Season categorical classes, individually, may or may not be significant.
In glm(),for each coefficient of every level of the categorical variable, a Wald test is performed to test whether the pairwise difference between the coefficient of the reference class and the other class is different from zero or not. 


If only one categorical class is insignificant, this does not imply that the whole variable is meaningless and should be removed from the model. 
Moreover, the categorical class coefficients denote the difference of each class to the reference class. 
Therefore, they only tell us about the pairwise differences between the levels. To test whether the categorical predictor, as a whole, is significant is equivalent to testing whether there is any heterogeneity in the means of the levels of the predictor.
Therefore, we need to create two models, one with Season and another without. Then compare the models using ANOVA and pick one from them.

```{r}
glm4 <- glm(Rain ~ TMAX+TMIN+WSF5, family = binomial(link = "logit"),data = train_df)
summary(glm4)
```

Let's compare the above two models(one with Seasons and other without) using Anova.


```{r}
anova(glm3, glm4, test='Chisq')
```

P value is significant and we reject the NULL hypothesis(Season's coefficient is zero).
Therefore, Season must remain in the model.
AIC for glm4 is 253.02, whereas AIC for glm3 is 256.4. It is another indication that glm4 is a better model.

We find the odds ratios and 95% CI:

```{r}
exp(cbind(OR = coef(glm3), confint(glm3)))
```

Residual Plot for GLM models are not as useful as the ones in LM.
```{r echo=FALSE}
par(mfrow=c(2,2))
plot(glm3)
par(mfrow=c(1,1))
```

Now that we have the model, let's go ahead and use this model to predict on the test data set.

By setting the parameter type='response', R will output probabilities in the form of P(y=1|X)

```{r echo=FALSE}
predicted <- predict(glm3,newdata = test_df,type = "response")
```

Predicted values are in probablity.
If probability of Rain > 0.5, we assume that it will rain that day and if probablity < 0.5, we can assume it won't rain that day.
This threshold can be changed based on subject knowledge.

```{r echo=FALSE}
predicted <- ifelse(predicted > 0.5,1,0)
```

Print the predictions

```{r warning=FALSE}
data.frame(Date = test_df$DATE,Rain_Actual = test_df$Rain, Predicted_Rain = predicted)
```


One of the most important performance indicator of a model is the confusion matrix.
It's a tabular representation of Actual vs Predicted values. This helps us to find the accuracy of the model and avoid overfitting.

```{r}
table(test_df$Rain, predicted)
```

Now, we calculate the accuracy of our prediction.

```{r}
accuracy <- 1-mean(predicted != test_df$Rain)
accuracy
```

**Accuracy** for our model is **0.8219 or 82.2%**. 
This is fair value for our model. Accuracy can be increased by checking the ROCR curve and making necessary adjustment in the probablity threshold.

Final step is to plot the **ROC(Receiver Operating Characteristic)** curve and find out the **AUC(area under curve)**.
ROC summarizes the model's performance by evaluating the trade offs between true positive rate (TPR or sensitivity) and false positive rate(1- specificity). 
The area under curve (AUC), referred to as index of accuracy(A) or concordance index, is a perfect performance metric for ROC curve. 
Higher the area under curve, better the prediction power of the model. Below is a sample ROC curve.
As a rule of thumb, a model with good predictive ability should have an AUC closer to 1 (=1 ideally) than to 0.5.

```{r}
ROCRPred <- prediction(predicted,test_df$Rain)
ROCRperf <- performance(ROCRPred, measure='tpr', x.measure='fpr')
```

Plot the ROC curve:

```{r}

plot(ROCRperf, colorize=TRUE)

```

Calculate the Area under curve(AUC)

```{r}
auc(test_df$Rain,predicted)
```

**AUC is 0.8239** which is an indication that our model is a good one.

##Summary
It's a good practice to start any given classification problem with logistic regression and go from there.
It sort of lays the benchmark accuracy for other non-linear models that one can try afterwards.


Logistic Regression is one of the most widely used classification algorithms today.
It has managed to survive Support Vector Machines, Random Forests and Boosting. 
It is also a crucial part of modern neural networks.
As Andrew Ng says, Neural networks are nothing but a stack of multiple logistic regression models.

Here's the [link](https://github.com/ppattnayak/SeattleRainLogisticRegression) to the code and data file.

##Citation:
[1] *http://faculty.cas.usf.edu/mbrannick/regression/Logistic.html*
